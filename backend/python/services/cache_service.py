# backend/python/services/cache_service.py
import redis
import json
import pickle
from functools import wraps
from datetime import datetime, timedelta
import logging
from typing import Any, Callable, Optional

class AdvancedCacheService:
    """
    Ø®Ø¯Ù…Ø© ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª Ù…ØªÙ‚Ø¯Ù…Ø© Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ø¢Ù„ÙŠ
    Ø§Ù„Ø­ÙØ§Ø¸ Ø§Ù„ÙƒØ§Ù…Ù„ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù…Ø¹ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
    """
    
    def __init__(self, host='localhost', port=6379, db=0):
        try:
            self.redis_client = redis.Redis(
                host=host, 
                port=port, 
                db=db,
                decode_responses=True,
                socket_connect_timeout=5,
                socket_timeout=5
            )
            # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„
            self.redis_client.ping()
            self.is_active = True
            logging.info("âœ… Redis cache connected successfully")
        except Exception as e:
            self.is_active = False
            logging.warning(f"âš ï¸ Redis not available, using memory cache: {e}")
            self.memory_cache = {}
    
    def cache_strategy(
        self, 
        ttl: int = 300,
        key_prefix: str = "cache",
        fallback: bool = True
    ):
        """
        Ø¯ÙŠÙƒÙˆØ±ator Ù„Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø³Ù„ÙˆÙƒ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        """
        def decorator(func: Callable) -> Callable:
            @wraps(func)  # Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ metadata Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            def wrapper(*args, **kwargs):
                # Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙØªØ§Ø­ ÙØ±ÙŠØ¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ø·ÙŠØ§Øª
                cache_key = f"{key_prefix}:{func.__name__}:{str(args)}:{str(kwargs)}"
                cache_key = cache_key.replace(" ", "")[:250]
                
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
                if self.is_active:
                    try:
                        cached_result = self.redis_client.get(cache_key)
                        if cached_result:
                            logging.debug(f"ğŸ“¦ Cache HIT for {func.__name__}")
                            return json.loads(cached_result)
                    except Exception as e:
                        logging.warning(f"Cache read error: {e}")
                
                # Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ†ØŒ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
                logging.debug(f"ğŸ”„ Cache MISS for {func.__name__}, executing function")
                result = func(*args, **kwargs)
                
                # ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†ØªÙŠØ¬Ø©
                if self.is_active and result is not None:
                    try:
                        self.redis_client.setex(
                            cache_key, 
                            ttl, 
                            json.dumps(result, default=str)
                        )
                    except Exception as e:
                        logging.warning(f"Cache write error: {e}")
                elif not self.is_active and fallback:
                    self.memory_cache[cache_key] = {
                        'data': result,
                        'expiry': datetime.now() + timedelta(seconds=ttl)
                    }
                
                return result  # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ø¯ÙˆÙ† ØªØ¹Ø¯ÙŠÙ„
            return wrapper
        return decorator
    
    def batch_cache_operations(self, operations: list):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¯ÙÙØ¹Ø§Øª Ù„Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª - ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©
        """
        if not self.is_active:
            return
            
        pipe = self.redis_client.pipeline()
        for op_type, key, value, ttl in operations:
            if op_type == 'set':
                pipe.setex(key, ttl, json.dumps(value, default=str))
            elif op_type == 'get':
                pipe.get(key)
            elif op_type == 'delete':
                pipe.delete(key)
        
        return pipe.execute()

# ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø®Ø¯Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ù„ÙˆÙƒ
cache_service = AdvancedCacheService()

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®Ø¯Ù…Ø© ÙÙŠ ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù…Ø¹ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙÙ‚Ø·
@cache_service.cache_strategy(ttl=60, key_prefix="exchange_data")
def get_cached_market_data(self, symbol: str, timeframe: str = '1h'):
    """
    Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù…Ø¹ Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
    """
    # Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø£ØµÙ„ÙŠ ÙŠØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡Ùˆ Ø¨Ø¯ÙˆÙ† ØªØ¹Ø¯ÙŠÙ„
    return self.get_market_data_original(symbol, timeframe)
