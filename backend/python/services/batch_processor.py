# backend/python/services/batch_processor.py
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor
import logging
from typing import List, Any, Callable
import time

class BatchProcessor:
    """
    Ù…Ø¹Ø§Ù„Ø¬ Ø¯ÙÙØ¹Ø§Øª Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© - ÙŠØ­Ø³Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù
    """
    
    def __init__(self, max_workers: int = 5, batch_size: int = 50):
        self.max_workers = max_workers
        self.batch_size = batch_size
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
    
    def process_batch_sync(self, data_list: List[Any], process_func: Callable):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¯ÙÙØ¹Ø§Øª Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø© - ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©
        """
        results = []
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø¯ÙØ¹Ø§Øª
        batches = [data_list[i:i + self.batch_size] 
                  for i in range(0, len(data_list), self.batch_size)]
        
        for batch in batches:
            try:
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯ÙØ¹Ø© (Ù†ÙØ³ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø­Ø§Ù„ÙŠØ©)
                batch_results = list(self.executor.map(process_func, batch))
                results.extend(batch_results)
                
                logging.info(f"âœ… Processed batch of {len(batch)} items")
                
                # Ø¥Ø±Ø§Ø­Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ù…Ù†Ø¹ Ø§Ù„Ø­Ù…Ù„ Ø§Ù„Ø²Ø§Ø¦Ø¯
                time.sleep(0.01)
                
            except Exception as e:
                logging.error(f"âŒ Batch processing error: {e}")
                # Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø± ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¹ Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©
                continue
        
        return results  # Ù†ÙØ³ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠ
    
    async def process_batch_async(self, data_list: List[Any], process_func: Callable):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¯ÙÙØ¹Ø§Øª ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†Ø© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
        """
        async def process_single(session, item):
            """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ù†ØµØ± ÙØ±Ø¯ÙŠ - Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø­Ø§Ù„ÙŠØ©"""
            try:
                return await process_func(session, item)
            except Exception as e:
                logging.error(f"Async processing error: {e}")
                return None
        
        async with aiohttp.ClientSession() as session:
            tasks = [process_single(session, item) for item in data_list]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
        # ØªØµÙÙŠØ© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙØ§Ø´Ù„Ø©
        successful_results = [r for r in results if not isinstance(r, Exception) and r is not None]
        logging.info(f"ğŸ”„ Async batch processed: {len(successful_results)}/{len(data_list)} successful")
        
        return successful_results

# ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø§Ù… Ø§Ù„Ø¯ÙØ¹Ø§Øª Ø¹Ù„Ù‰ Ø®Ø¯Ù…Ø§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠØ©
batch_processor = BatchProcessor(max_workers=10, batch_size=100)

def process_multiple_orders_optimized(orders_data):
    """
    Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© Ù…Ù† Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© - Ù†ÙØ³ Ø§Ù„ÙˆØ¸ÙŠÙØ© Ù…Ø¹ Ø£Ø¯Ø§Ø¡ Ø£ÙØ¶Ù„
    """
    from backend.python.services.exchange_service import ExchangeService
    
    exchange_service = ExchangeService()
    
    def process_single_order(order_data):
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ø¨Ø¯ÙˆÙ† ØªØ¹Ø¯ÙŠÙ„
        return exchange_service.place_order(
            symbol=order_data['symbol'],
            order_type=order_data['order_type'],
            quantity=order_data['quantity'],
            price=order_data.get('price')
        )
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯ÙØ¹Ø§Øª Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£ØµÙ„ÙŠØ©
    return batch_processor.process_batch_sync(orders_data, process_single_order)
