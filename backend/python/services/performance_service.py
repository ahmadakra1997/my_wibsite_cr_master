"""
Ø®Ø¯Ù…Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© - Ø§Ù„Ø¥ØµØ¯Ø§Ø± 4.0
Ù†Ø¸Ø§Ù… Ø´Ø§Ù…Ù„ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù…Ø¹ ØªØ­Ù„ÙŠÙ„Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
"""

import os
import logging
import asyncio
import time
import psutil
import gc
from typing import Dict, List, Optional, Any, Callable
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum
import threading
from concurrent.futures import ThreadPoolExecutor
from functools import wraps
import cachetools
import tracemalloc
import weakref

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø¬Ù„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
logger = logging.getLogger(__name__)

class PerformanceLevel(Enum):
    """Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
    OPTIMAL = "optimal"
    GOOD = "good"
    WARNING = "warning"
    CRITICAL = "critical"

class MemoryProfile(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
    LOW_MEMORY = "low_memory"
    BALANCED = "balanced"
    HIGH_PERFORMANCE = "high_performance"

@dataclass
class PerformanceMetrics:
    """Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø´Ø§Ù…Ù„Ø©"""
    timestamp: datetime
    cpu_usage: float
    memory_usage: float
    memory_available: float
    disk_io: Dict[str, float]
    network_io: Dict[str, float]
    active_threads: int
    active_processes: int
    gc_stats: Dict[str, Any]
    performance_level: PerformanceLevel

@dataclass
class MemorySnapshot:
    """Ù„Ù‚Ø·Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
    snapshot_id: str
    timestamp: datetime
    memory_info: Dict[str, Any]
    object_counts: Dict[str, int]
    memory_leaks: List[Dict[str, Any]]

class AdvancedCacheManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
    
    def __init__(self):
        self.caches = {}
        self.hit_rates = {}
        self.setup_caches()
    
    def setup_caches(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø°ÙˆØ§ÙƒØ± Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ø§Ù„Ù…ØªØ®ØµØµØ©"""
        try:
            # Ø°Ø§ÙƒØ±Ø© Ù…Ø¤Ù‚ØªØ© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ø§Ø®Ù†Ø© (5 Ø¯Ù‚Ø§Ø¦Ù‚)
            self.caches['hot_data'] = cachetools.TTLCache(
                maxsize=int(os.getenv('HOT_CACHE_SIZE', '1000')),
                ttl=int(os.getenv('HOT_CACHE_TTL', '300'))
            )
            
            # Ø°Ø§ÙƒØ±Ø© Ù…Ø¤Ù‚ØªØ© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨Ø§Ø±Ø¯Ø© (30 Ø¯Ù‚ÙŠÙ‚Ø©)
            self.caches['cold_data'] = cachetools.TTLCache(
                maxsize=int(os.getenv('COLD_CACHE_SIZE', '500')),
                ttl=int(os.getenv('COLD_CACHE_TTL', '1800'))
            )
            
            # Ø°Ø§ÙƒØ±Ø© Ù…Ø¤Ù‚ØªØ© Ù„Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª (10 Ø¯Ù‚Ø§Ø¦Ù‚)
            self.caches['query_cache'] = cachetools.LRUCache(
                maxsize=int(os.getenv('QUERY_CACHE_SIZE', '2000'))
            )
            
            # Ø°Ø§ÙƒØ±Ø© Ù…Ø¤Ù‚ØªØ© Ù„Ù„Ø¬Ù„Ø³Ø§Øª (1 Ø³Ø§Ø¹Ø©)
            self.caches['session_cache'] = cachetools.TTLCache(
                maxsize=int(os.getenv('SESSION_CACHE_SIZE', '100')),
                ttl=int(os.getenv('SESSION_CACHE_TTL', '3600'))
            )
            
            # ØªÙ‡ÙŠØ¦Ø© Ù…Ø¹Ø¯Ù„Ø§Øª Ø§Ù„Ø¶Ø±Ø¨
            for cache_name in self.caches:
                self.hit_rates[cache_name] = {'hits': 0, 'misses': 0}
                
            logger.info("âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¯ÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø°ÙˆØ§ÙƒØ± Ø§Ù„Ù…Ø¤Ù‚ØªØ©: {e}")
            raise
    
    def get(self, cache_name: str, key: str) -> Any:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©"""
        try:
            if cache_name not in self.caches:
                self.hit_rates[cache_name]['misses'] += 1
                return None
            
            value = self.caches[cache_name].get(key)
            if value is not None:
                self.hit_rates[cache_name]['hits'] += 1
            else:
                self.hit_rates[cache_name]['misses'] += 1
                
            return value
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ© {cache_name}: {e}")
            return None
    
    def set(self, cache_name: str, key: str, value: Any, ttl: Optional[int] = None) -> bool:
        """ØªØ®Ø²ÙŠÙ† Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©"""
        try:
            if cache_name not in self.caches:
                return False
            
            if ttl and hasattr(self.caches[cache_name], 'ttl'):
                # Ø¥Ù†Ø´Ø§Ø¡ Ø°Ø§ÙƒØ±Ø© Ù…Ø¤Ù‚ØªØ© Ù…Ø¤Ù‚ØªØ© Ø¥Ø°Ø§ ØªÙ… ØªÙˆÙÙŠØ± TTL Ù…Ø®ØµØµ
                temp_cache = cachetools.TTLCache(
                    maxsize=self.caches[cache_name].maxsize,
                    ttl=ttl
                )
                temp_cache[key] = value
                self.caches[cache_name][key] = value
            else:
                self.caches[cache_name][key] = value
                
            return True
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ© {cache_name}: {e}")
            return False
    
    def get_hit_rate(self, cache_name: str) -> float:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¶Ø±Ø¨ Ù„Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©"""
        if cache_name not in self.hit_rates:
            return 0.0
        
        stats = self.hit_rates[cache_name]
        total = stats['hits'] + stats['misses']
        return stats['hits'] / total if total > 0 else 0.0
    
    def clear_cache(self, cache_name: str) -> bool:
        """Ù…Ø³Ø­ Ø°Ø§ÙƒØ±Ø© ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª Ù…Ø­Ø¯Ø¯Ø©"""
        try:
            if cache_name in self.caches:
                self.caches[cache_name].clear()
                self.hit_rates[cache_name] = {'hits': 0, 'misses': 0}
                return True
            return False
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ© {cache_name}: {e}")
            return False
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø°ÙˆØ§ÙƒØ± Ø§Ù„Ù…Ø¤Ù‚ØªØ©"""
        stats = {}
        for cache_name, cache in self.caches.items():
            stats[cache_name] = {
                'size': len(cache),
                'max_size': cache.maxsize,
                'hit_rate': self.get_hit_rate(cache_name),
                'currsize': cache.currsize
            }
        return stats

class MemoryOptimizer:
    """Ù…Ø­Ø³Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
    
    def __init__(self):
        self.memory_threshold = float(os.getenv('MEMORY_THRESHOLD', '80.0'))
        self.cleanup_interval = int(os.getenv('MEMORY_CLEANUP_INTERVAL', '60'))
        self.performance_mode = os.getenv('PERFORMANCE_MODE', 'balanced')
        self.setup_memory_profiling()
    
    def setup_memory_profiling(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        try:
            tracemalloc.start()
            self.snapshots = []
            self.leak_detector = MemoryLeakDetector()
            logger.info("âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø­Ø³Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {e}")
    
    def optimize_memory_usage(self) -> Dict[str, Any]:
        """ØªØ­Ø³ÙŠÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        try:
            optimization_report = {
                'timestamp': datetime.now(),
                'actions_taken': [],
                'memory_freed': 0,
                'optimization_level': 'none'
            }
            
            # Ø¬Ù…Ø¹ Ø§Ù„Ù‚Ù…Ø§Ù…Ø© Ø§Ù„Ù‚Ø³Ø±ÙŠØ©
            freed_objects = gc.collect()
            if freed_objects > 0:
                optimization_report['actions_taken'].append('forced_garbage_collection')
                optimization_report['memory_freed'] += freed_objects
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø­Ø§Ù„ÙŠ
            memory_info = self.analyze_memory_usage()
            
            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†Ù…Ø· Ø§Ù„Ø£Ø¯Ø§Ø¡
            if self.performance_mode == 'low_memory':
                optimization_report.update(self._apply_low_memory_optimizations(memory_info))
            elif self.performance_mode == 'high_performance':
                optimization_report.update(self._apply_high_performance_optimizations(memory_info))
            else:  # balanced
                optimization_report.update(self._apply_balanced_optimizations(memory_info))
            
            # ØªØ­Ø¯ÙŠØ« Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ­Ø³ÙŠÙ†
            optimization_report['optimization_level'] = self._calculate_optimization_level(
                optimization_report['memory_freed']
            )
            
            logger.info(f"ğŸ¯ ØªÙ… ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {optimization_report}")
            return optimization_report
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {e}")
            return {'error': str(e)}
    
    def analyze_memory_usage(self) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø­Ø§Ù„ÙŠ"""
        try:
            process = psutil.Process()
            memory_info = process.memory_info()
            memory_percent = process.memory_percent()
            
            # ØªØ­Ù„ÙŠÙ„ ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            object_analysis = self._analyze_objects()
            
            # Ø§ÙƒØªØ´Ø§Ù ØªØ³Ø±ÙŠØ¨Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            memory_leaks = self.leak_detector.detect_leaks()
            
            return {
                'rss': memory_info.rss,  # Resident Set Size
                'vms': memory_info.vms,  # Virtual Memory Size
                'percent': memory_percent,
                'available_memory': psutil.virtual_memory().available,
                'object_counts': object_analysis,
                'memory_leaks': memory_leaks,
                'timestamp': datetime.now()
            }
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {e}")
            return {}
    
    def _analyze_objects(self) -> Dict[str, int]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        try:
            objects = gc.get_objects()
            object_counts = {}
            
            for obj in objects:
                obj_type = type(obj).__name__
                object_counts[obj_type] = object_counts.get(obj_type, 0) + 1
            
            return dict(sorted(object_counts.items(), key=lambda x: x[1], reverse=True)[:10])
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª: {e}")
            return {}
    
    def _apply_low_memory_optimizations(self, memory_info: Dict) -> Dict:
        """ØªØ·Ø¨ÙŠÙ‚ ØªØ­Ø³ÙŠÙ†Ø§Øª ÙˆØ¶Ø¹ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ù†Ø®ÙØ¶Ø©"""
        optimizations = {'actions_taken': [], 'memory_freed': 0}
        
        # ØªÙ†Ø¸ÙŠÙ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
        cache_manager = AdvancedCacheManager()
        for cache_name in cache_manager.caches:
            old_size = len(cache_manager.caches[cache_name])
            cache_manager.clear_cache(cache_name)
            optimizations['memory_freed'] += old_size
            optimizations['actions_taken'].append(f'cleared_cache_{cache_name}')
        
        # ØªÙ†Ø¸ÙŠÙ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
        if hasattr(gc, 'free'):
            gc.free()
            optimizations['actions_taken'].append('system_memory_free')
        
        return optimizations
    
    def _apply_high_performance_optimizations(self, memory_info: Dict) -> Dict:
        """ØªØ·Ø¨ÙŠÙ‚ ØªØ­Ø³ÙŠÙ†Ø§Øª ÙˆØ¶Ø¹ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù„ÙŠ"""
        optimizations = {'actions_taken': [], 'memory_freed': 0}
        
        # ØªØ­Ø³ÙŠÙ† Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù„ÙˆØµÙˆÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹
        cache_manager = AdvancedCacheManager()
        for cache_name in ['hot_data', 'query_cache']:
            cache_manager.caches[cache_name].maxsize = min(
                cache_manager.caches[cache_name].maxsize * 2,
                10000  # Ø­Ø¯ Ø£Ù‚ØµÙ‰
            )
            optimizations['actions_taken'].append(f'optimized_cache_{cache_name}')
        
        return optimizations
    
    def _apply_balanced_optimizations(self, memory_info: Dict) -> Dict:
        """ØªØ·Ø¨ÙŠÙ‚ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù…ØªÙˆØ§Ø²Ù†"""
        optimizations = {'actions_taken': [], 'memory_freed': 0}
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù†ØªÙ‚Ø§Ø¦ÙŠ Ù„Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
        cache_manager = AdvancedCacheManager()
        cache_stats = cache_manager.get_cache_stats()
        
        for cache_name, stats in cache_stats.items():
            if stats['hit_rate'] < 0.3:  # Ù…Ø¹Ø¯Ù„ Ø¶Ø±Ø¨ Ù…Ù†Ø®ÙØ¶
                cache_manager.clear_cache(cache_name)
                optimizations['actions_taken'].append(f'cleaned_low_hit_cache_{cache_name}')
        
        return optimizations
    
    def _calculate_optimization_level(self, memory_freed: int) -> str:
        """Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ­Ø³ÙŠÙ†"""
        if memory_freed > 1000000:  # 1MB
            return 'high'
        elif memory_freed > 100000:  # 100KB
            return 'medium'
        else:
            return 'low'
    
    def create_memory_snapshot(self) -> MemorySnapshot:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù„Ù‚Ø·Ø© Ù„Ù„Ø°Ø§ÙƒØ±Ø©"""
        try:
            snapshot_id = f"snapshot_{int(time.time())}"
            memory_info = self.analyze_memory_usage()
            object_counts = self._analyze_objects()
            memory_leaks = self.leak_detector.detect_leaks()
            
            snapshot = MemorySnapshot(
                snapshot_id=snapshot_id,
                timestamp=datetime.now(),
                memory_info=memory_info,
                object_counts=object_counts,
                memory_leaks=memory_leaks
            )
            
            self.snapshots.append(snapshot)
            # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¢Ø®Ø± 10 Ù„Ù‚Ø·Ø§Øª ÙÙ‚Ø·
            self.snapshots = self.snapshots[-10:]
            
            return snapshot
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù„Ù‚Ø·Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {e}")
            return None
    
    def compare_snapshots(self, snapshot1: MemorySnapshot, snapshot2: MemorySnapshot) -> Dict[str, Any]:
        """Ù…Ù‚Ø§Ø±Ù†Ø© Ù„Ù‚Ø·ØªÙŠÙ† Ù„Ù„Ø°Ø§ÙƒØ±Ø©"""
        try:
            memory_diff = snapshot2.memory_info['rss'] - snapshot1.memory_info['rss']
            object_diffs = {}
            
            # Ù…Ù‚Ø§Ø±Ù†Ø© Ø¹Ø¯Ø¯ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª
            for obj_type, count2 in snapshot2.object_counts.items():
                count1 = snapshot1.object_counts.get(obj_type, 0)
                object_diffs[obj_type] = count2 - count1
            
            return {
                'memory_difference_bytes': memory_diff,
                'object_differences': object_diffs,
                'new_memory_leaks': len(snapshot2.memory_leaks) - len(snapshot1.memory_leaks),
                'time_elapsed_seconds': (snapshot2.timestamp - snapshot1.timestamp).total_seconds()
            }
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù„Ù‚Ø·Ø§Øª: {e}")
            return {}

class MemoryLeakDetector:
    """ÙƒØ§Ø´Ù ØªØ³Ø±ÙŠØ¨Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
    
    def __init__(self):
        self.object_references = weakref.WeakSet()
        self.reference_snapshots = []
    
    def track_object(self, obj: Any) -> None:
        """ØªØªØ¨Ø¹ ÙƒØ§Ø¦Ù† Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ØªØ³Ø±ÙŠØ¨Ø§Øª"""
        self.object_references.add(obj)
    
    def detect_leaks(self) -> List[Dict[str, Any]]:
        """Ø§ÙƒØªØ´Ø§Ù ØªØ³Ø±ÙŠØ¨Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        try:
            leaks = []
            current_objects = set(gc.get_objects())
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ ØªÙ†Ø¸ÙŠÙÙ‡Ø§
            for obj in current_objects:
                if self._is_potential_leak(obj):
                    leaks.append({
                        'object_type': type(obj).__name__,
                        'object_size': self._estimate_object_size(obj),
                        'reference_count': sys.getrefcount(obj) - 1,  # Ø·Ø±Ø­ Ø§Ù„Ù…Ø±Ø¬Ø¹ Ø§Ù„Ù…Ø¤Ù‚Øª
                        'creation_time': getattr(obj, '_creation_time', None)
                    })
            
            return leaks[:50]  # Ø¥Ø±Ø¬Ø§Ø¹ Ø£ÙˆÙ„ 50 ØªØ³Ø±ÙŠØ¨ Ù…Ø­ØªÙ…Ù„ ÙÙ‚Ø·
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ØªØ³Ø±ÙŠØ¨Ø§Øª: {e}")
            return []
    
    def _is_potential_leak(self, obj: Any) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙƒØ§Ø¦Ù† ØªØ³Ø±ÙŠØ¨ Ù…Ø­ØªÙ…Ù„"""
        try:
            # Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø¶Ù…Ù†Ø©
            if type(obj).__module__ == 'builtins':
                return False
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹
            ref_count = sys.getrefcount(obj) - 1
            if ref_count > 100:  # Ø¹Ø¯Ø¯ Ù…Ø±Ø§Ø¬Ø¹ ÙƒØ¨ÙŠØ±
                return True
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„ÙƒØ§Ø¦Ù†
            obj_size = self._estimate_object_size(obj)
            if obj_size > 1000000:  # ÙƒØ§Ø¦Ù† ÙƒØ¨ÙŠØ± (>1MB)
                return True
            
            return False
        except:
            return False
    
    def _estimate_object_size(self, obj: Any) -> int:
        """ØªÙ‚Ø¯ÙŠØ± Ø­Ø¬Ù… Ø§Ù„ÙƒØ§Ø¦Ù†"""
        try:
            return sys.getsizeof(obj)
        except:
            return 0

class PerformanceMonitor:
    """Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
    
    def __init__(self):
        self.metrics_history = []
        self.alert_thresholds = self._load_alert_thresholds()
        self.monitoring_interval = int(os.getenv('PERF_MONITOR_INTERVAL', '30'))
        self.is_monitoring = False
        self.monitor_thread = None
        
    def _load_alert_thresholds(self) -> Dict[str, float]:
        """ØªØ­Ù…ÙŠÙ„ Ø¹ØªØ¨Ø§Øª Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡"""
        return {
            'cpu_usage': float(os.getenv('CPU_ALERT_THRESHOLD', '80.0')),
            'memory_usage': float(os.getenv('MEMORY_ALERT_THRESHOLD', '85.0')),
            'memory_available': float(os.getenv('MEMORY_AVAILABLE_THRESHOLD', '1073741824')),  # 1GB
            'disk_io_wait': float(os.getenv('DISK_IO_THRESHOLD', '50.0')),
            'response_time': float(os.getenv('RESPONSE_TIME_THRESHOLD', '5.0'))
        }
    
    def start_monitoring(self) -> None:
        """Ø¨Ø¯Ø¡ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        if self.is_monitoring:
            return
        
        self.is_monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self.monitor_thread.start()
        logger.info("ğŸ¯ Ø¨Ø¯Ø¡ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©")
    
    def stop_monitoring(self) -> None:
        """Ø¥ÙŠÙ‚Ø§Ù Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        self.is_monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5.0)
        logger.info("ğŸ›‘ Ø¥ÙŠÙ‚Ø§Ù Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡")
    
    def _monitoring_loop(self) -> None:
        """Ø­Ù„Ù‚Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
        while self.is_monitoring:
            try:
                metrics = self.capture_performance_metrics()
                self.metrics_history.append(metrics)
                
                # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø³Ø¬Ù„ Ø¢Ø®Ø± 1000 Ù‚ÙŠØ§Ø³
                self.metrics_history = self.metrics_history[-1000:]
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª
                alerts = self.check_alerts(metrics)
                if alerts:
                    self.handle_alerts(alerts, metrics)
                
                time.sleep(self.monitoring_interval)
                
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ù„Ù‚Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©: {e}")
                time.sleep(self.monitoring_interval)
    
    def capture_performance_metrics(self) -> PerformanceMetrics:
        """ØªÙ‚Ø§Ø· Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ©
            cpu_usage = psutil.cpu_percent(interval=1)
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            memory = psutil.virtual_memory()
            memory_usage = memory.percent
            memory_available = memory.available
            
            # Ø¥Ø¯Ø®Ø§Ù„/Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ù‚Ø±Øµ
            disk_io = psutil.disk_io_counters()
            disk_io_data = {
                'read_bytes': disk_io.read_bytes if disk_io else 0,
                'write_bytes': disk_io.write_bytes if disk_io else 0,
                'read_time': disk_io.read_time if disk_io else 0,
                'write_time': disk_io.write_time if disk_io else 0
            }
            
            # Ø¥Ø¯Ø®Ø§Ù„/Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ø´Ø¨ÙƒØ©
            network_io = psutil.net_io_counters()
            network_io_data = {
                'bytes_sent': network_io.bytes_sent if network_io else 0,
                'bytes_recv': network_io.bytes_recv if network_io else 0,
                'packets_sent': network_io.packets_sent if network_io else 0,
                'packets_recv': network_io.packets_recv if network_io else 0
            }
            
            # Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„Ø®ÙŠÙˆØ· ÙˆØ§Ù„Ø¹Ù…Ù„ÙŠØ§Øª
            active_threads = threading.active_count()
            active_processes = len(psutil.pids())
            
            # Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø¬Ø§Ù…Ø¹ Ø§Ù„Ù‚Ù…Ø§Ù…Ø©
            gc_stats = {
                'collections': gc.get_count(),
                'thresholds': gc.get_threshold(),
                'enabled': gc.isenabled()
            }
            
            # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ø¯Ø§Ø¡
            performance_level = self._determine_performance_level(
                cpu_usage, memory_usage, memory_available
            )
            
            return PerformanceMetrics(
                timestamp=datetime.now(),
                cpu_usage=cpu_usage,
                memory_usage=memory_usage,
                memory_available=memory_available,
                disk_io=disk_io_data,
                network_io=network_io_data,
                active_threads=active_threads,
                active_processes=active_processes,
                gc_stats=gc_stats,
                performance_level=performance_level
            )
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ‚Ø§Ø· Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡: {e}")
            return PerformanceMetrics(
                timestamp=datetime.now(),
                cpu_usage=0,
                memory_usage=0,
                memory_available=0,
                disk_io={},
                network_io={},
                active_threads=0,
                active_processes=0,
                gc_stats={},
                performance_level=PerformanceLevel.CRITICAL
            )
    
    def _determine_performance_level(self, cpu_usage: float, memory_usage: float, memory_available: float) -> PerformanceLevel:
        """ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        if cpu_usage > 90 or memory_usage > 90 or memory_available < 536870912:  # 512MB
            return PerformanceLevel.CRITICAL
        elif cpu_usage > 75 or memory_usage > 80 or memory_available < 1073741824:  # 1GB
            return PerformanceLevel.WARNING
        elif cpu_usage > 50 or memory_usage > 65:
            return PerformanceLevel.GOOD
        else:
            return PerformanceLevel.OPTIMAL
    
    def check_alerts(self, metrics: PerformanceMetrics) -> List[Dict[str, Any]]:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª"""
        alerts = []
        
        # ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ©
        if metrics.cpu_usage > self.alert_thresholds['cpu_usage']:
            alerts.append({
                'type': 'high_cpu_usage',
                'level': 'warning',
                'value': metrics.cpu_usage,
                'threshold': self.alert_thresholds['cpu_usage'],
                'message': f'Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ø§Ù„ÙŠ Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ©: {metrics.cpu_usage}%'
            })
        
        # ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        if metrics.memory_usage > self.alert_thresholds['memory_usage']:
            alerts.append({
                'type': 'high_memory_usage',
                'level': 'warning',
                'value': metrics.memory_usage,
                'threshold': self.alert_thresholds['memory_usage'],
                'message': f'Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ø§Ù„ÙŠ Ù„Ù„Ø°Ø§ÙƒØ±Ø©: {metrics.memory_usage}%'
            })
        
        # ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©
        if metrics.memory_available < self.alert_thresholds['memory_available']:
            alerts.append({
                'type': 'low_available_memory',
                'level': 'critical',
                'value': metrics.memory_available,
                'threshold': self.alert_thresholds['memory_available'],
                'message': f'Ø°Ø§ÙƒØ±Ø© Ù…ØªØ§Ø­Ø© Ù…Ù†Ø®ÙØ¶Ø©: {metrics.memory_available / 1024/1024/1024:.2f}GB'
            })
        
        return alerts
    
    def handle_alerts(self, alerts: List[Dict], metrics: PerformanceMetrics) -> None:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª"""
        for alert in alerts:
            logger.warning(f"âš ï¸  ØªÙ†Ø¨ÙŠÙ‡ Ø£Ø¯Ø§Ø¡: {alert['message']}")
            
            # Ø§ØªØ®Ø§Ø° Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ù„Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ø­Ø±Ø¬Ø©
            if alert['level'] == 'critical':
                self._handle_critical_alert(alert, metrics)
    
    def _handle_critical_alert(self, alert: Dict, metrics: PerformanceMetrics) -> None:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ø­Ø±Ø¬Ø©"""
        try:
            if alert['type'] == 'low_available_memory':
                # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø°Ø§ÙƒØ±Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
                optimizer = MemoryOptimizer()
                optimizer.optimize_memory_usage()
                logger.info("ğŸ”„ ØªÙ… ØªØ´ØºÙŠÙ„ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¨Ø³Ø¨Ø¨ ØªÙ†Ø¨ÙŠÙ‡ Ø­Ø±Ø¬")
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡ Ø§Ù„Ø­Ø±Ø¬: {e}")
    
    def get_performance_report(self, hours: int = 24) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        try:
            cutoff_time = datetime.now() - timedelta(hours=hours)
            recent_metrics = [m for m in self.metrics_history if m.timestamp > cutoff_time]
            
            if not recent_metrics:
                return {'error': 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ©'}
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª
            avg_cpu = sum(m.cpu_usage for m in recent_metrics) / len(recent_metrics)
            avg_memory = sum(m.memory_usage for m in recent_metrics) / len(recent_metrics)
            
            # ØªÙˆØ²ÙŠØ¹ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
            performance_distribution = {}
            for level in PerformanceLevel:
                performance_distribution[level.value] = len(
                    [m for m in recent_metrics if m.performance_level == level]
                )
            
            return {
                'report_period_hours': hours,
                'metrics_analyzed': len(recent_metrics),
                'average_cpu_usage': round(avg_cpu, 2),
                'average_memory_usage': round(avg_memory, 2),
                'performance_distribution': performance_distribution,
                'current_performance_level': self.metrics_history[-1].performance_level.value if self.metrics_history else 'unknown',
                'alerts_last_24h': len([m for m in recent_metrics if any(self.check_alerts(m))]),
                'recommendations': self._generate_recommendations(recent_metrics)
            }
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡: {e}")
            return {'error': str(e)}
    
    def _generate_recommendations(self, metrics: List[PerformanceMetrics]) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        recommendations = []
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ©
        high_cpu_periods = len([m for m in metrics if m.cpu_usage > 80])
        if high_cpu_periods > len(metrics) * 0.3:  # 30% Ù…Ù† Ø§Ù„ÙˆÙ‚Øª
            recommendations.append("ØªÙÙƒØ± ÙÙŠ ØªØ­Ø³ÙŠÙ† ÙƒÙØ§Ø¡Ø© Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø£Ùˆ Ø²ÙŠØ§Ø¯Ø© Ù…ÙˆØ§Ø±Ø¯ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ©")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        high_memory_periods = len([m for m in metrics if m.memory_usage > 85])
        if high_memory_periods > len(metrics) * 0.2:  # 20% Ù…Ù† Ø§Ù„ÙˆÙ‚Øª
            recommendations.append("ØªÙÙƒØ± ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø£Ùˆ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©")
        
        # ØªØ­Ù„ÙŠÙ„ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù…
        critical_periods = len([m for m in metrics if m.performance_level == PerformanceLevel.CRITICAL])
        if critical_periods > 0:
            recommendations.append("Ù‡Ù†Ø§Ùƒ ÙØªØ±Ø§Øª Ø­Ø±Ø¬Ø© ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¹Ø§Ø¬Ù„Ø©")
        
        return recommendations

# Ø¯ÙˆØ§Ù„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
def performance_timer(func: Callable) -> Callable:
    """Ù…ØµØ­Ø­ Ù„Ù‚ÙŠØ§Ø³ ÙˆÙ‚Øª ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯ÙˆØ§Ù„"""
    @wraps(func)
    async def async_wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            return result
        finally:
            execution_time = time.time() - start_time
            logger.debug(f"â±ï¸  ÙˆÙ‚Øª ØªÙ†ÙÙŠØ° {func.__name__}: {execution_time:.4f} Ø«Ø§Ù†ÙŠØ©")
    
    @wraps(func)
    def sync_wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            return result
        finally:
            execution_time = time.time() - start_time
            logger.debug(f"â±ï¸  ÙˆÙ‚Øª ØªÙ†ÙÙŠØ° {func.__name__}: {execution_time:.4f} Ø«Ø§Ù†ÙŠØ©")
    
    return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper

def memory_intensive_task(func: Callable) -> Callable:
    """Ù…ØµØ­Ø­ Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…ÙƒØ«ÙØ© Ø°Ø§ÙƒØ±ÙŠØ§Ù‹"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ØªØ§Ø­Ø© Ù‚Ø¨Ù„ Ø§Ù„ØªÙ†ÙÙŠØ°
        memory = psutil.virtual_memory()
        if memory.available < 1073741824:  # 1GB
            logger.warning("âš ï¸  Ø°Ø§ÙƒØ±Ø© Ù…Ù†Ø®ÙØ¶Ø© Ù‚Ø¨Ù„ ØªÙ†ÙÙŠØ° Ù…Ù‡Ù…Ø© Ù…ÙƒØ«ÙØ©")
        
        result = func(*args, **kwargs)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†ÙÙŠØ°
        memory_after = psutil.virtual_memory()
        memory_used = memory_after.used - memory.used
        
        if memory_used > 536870912:  # 512MB
            logger.info(f"ğŸ§  Ø§Ù„Ù…Ù‡Ù…Ø© {func.__name__} Ø§Ø³ØªØ®Ø¯Ù…Øª {memory_used / 1024/1024:.2f}MB")
        
        return result
    return wrapper

# Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ© Ù„Ù„Ø®Ø¯Ù…Ø©
performance_monitor = PerformanceMonitor()
cache_manager = AdvancedCacheManager()
memory_optimizer = MemoryOptimizer()

# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙˆØ§ÙÙ‚
def get_cache_manager() -> AdvancedCacheManager:
    """Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¯ÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©"""
    return cache_manager

def get_performance_monitor() -> PerformanceMonitor:
    """Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
    return performance_monitor

def optimize_system_memory() -> Dict[str, Any]:
    """Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
    return memory_optimizer.optimize_memory_usage()

if __name__ == "__main__":
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ø¯Ù…Ø§Øª
    async def test_performance_services():
        print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø©...")
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
        cache_manager.set('hot_data', 'test_key', {'data': 'test_value'})
        cached_value = cache_manager.get('hot_data', 'test_key')
        print(f"âœ… Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©: {cached_value}")
        
        # Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        optimization_report = memory_optimizer.optimize_memory_usage()
        print(f"âœ… ØªÙ‚Ø±ÙŠØ± ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {optimization_report}")
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø£Ø¯Ø§Ø¡
        performance_monitor.start_monitoring()
        await asyncio.sleep(2)
        
        performance_report = performance_monitor.get_performance_report(1)
        print(f"âœ… ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡: {performance_report}")
        
        performance_monitor.stop_monitoring()
    
    asyncio.run(test_performance_services())
